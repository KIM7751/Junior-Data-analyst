신경망 이전의 연구

- 사람이 직접 패턴 파악

	ex) 눈, 코, 입 / 손글씨 -> 예측 

- 인공지능의 신경망은 사람이 했던 패턴 파악을 직접 진행함

-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론(Perceptron)

- 1958년 딥러닝의 가장 기본 단위가 생겨남, 단위만으로도 간단한 회귀, 분류가 가능함

- 사람의 신경 세포를 보면 input 과 output의 구조를 가지고 있음

- input 신호를 전달 받는 부분 x1 ~ xn, n개의 돌기로 부터 전달 받음, 모두 하나로 합쳐지게 됨

- output 하나로 합쳐졌던 신호들이 y1 ~ ym, m개의 다른 신호들로 전달함 

- 이러한 신경 세포를 본떠 만든 것이 "퍼셉트론"

-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론(Perceptron)의 기본 구조

- 입력 부분

	x1, x2 입력값

- 가중치 

	w1, w2 가중치, 들어오는 신호에 대해서 얼마나 증폭시킬지 판단함
	
	입력값 x1, x2와 각각을 곱함 

- bias

	w0 bias, 입력 하는 값에 상관없이 무조건 입력되는 값

	어떤 값이던지 가능하지만 무조건 입력되는 값임

- y

	출력이 나오기 전 [입력값*가중치 + bias]은 모두 더해지고( ∑ )  마지막으로 활성화 함수(activation function)을 거져 최종적인 y값이 나옴

-----------------------------------------------------------------------------------------------------------------------------------

활성화 함수(activation function)

- activation(x) = { 1, x>=0   0, x<0 } 

	0이거나 보다 크면 1로 매핑
	
	0보다 작으면 0으로 매핑


-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론 동작 예시

	ex1) x1 = 1, x2 = 0, w1 = 2, w2 =1, bias = -0.5

		∑ = w1x1 + w2x2 + bias

	   	   = 2 + 0 - 0.5

	   	   = 1.5

		activation function(1.5) = 1

	ex2) x1 = 신작드라마 수 , x2 = 여가 시간, w1 = 드라마 시청 욕구로 인한 영향, w2 = 여가 시간에 따른 공부하고 싶은 정도, w0 = 다른 영향을 받지 않고 학습을 해야 한다는 의지

		∑ = w1x1 + w2x2 + bias

		activation function(x)

-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론을 활용한 선형 분류기

- 퍼셉트론은 선형 분류기로써 데이터 분류 가능함

- 하지만 하나의 선으로 분류할 수 없는 문제가 등장함 

- 이러한 문제가 나타나 1969년 "첫번째 AI 겨울(First AI winter)"이라고 불리는 빙하기가 찾아옴

-----------------------------------------------------------------------------------------------------------------------------------

다층 퍼셉트론

- 1986년 1차 빙하기가 해소됨

- 비 선형적인 문제 해결 

	단층 퍼셉트론은 입력층과 출력층만 존재


- 단층 퍼셉트론을 여러 층으로 쌓아보자 -> 다층 퍼셉트론 

- 단층 퍼셉트론으로 구분 하지 못했던 "결과"를 조합해 "새로운 결과"로구분해내는 모습을 볼 수 있음 

- 히든 레이어(Hidden Layer) : 입력층과 출력층 사이의 모든 Layer들

- 히든 레이어가 많아 진다면 깊은 신경망이라는 의미의 Deep Learning 단어를 사용함

	장점 : 분류할 수 있는 방법이 많아져 성능이 높아짐

	단점 : 가중치 w0, w1, w2, wn n+1 개의 가중치는 1개 퍼셉트론에 해당함 

	        즉, 다층 퍼셉트론에 필요한 가중치가 무수히 많아짐

	        마냥 깊게만 만들 수 없음 

-----------------------------------------------------------------------------------------------------------------------------------

딥러닝 모델의 학습 방법

- 딥러닝 모델이란 ? : 히든층이 많아진다면 깊은 신경망이라는 의미의 Deep Learning 단어 사용

- 딥러닝 모델의 구성 요소

	1) Node/Unit(노드/유닛) : 각 층을 구성하는 요소

	2) Weight(가중치) : 노드간의 연결강도

	3) Layer(레이어) : 모델을 구성하는 층

		i) Hidden Layer(히든 레이어) : 입력단과 출력단 사이에 위치한 레이어


- 어떻게 학습하는가 ? : 예측값과 실제값 간의 오차값을 최소화하기 위해 오차값을 최소화하는 모델의 인자를 찾는 알고리즘 적용
		
		    = 손실 함수를 최소화하는 가중치를 찾기 위해 최적화 알고리즘을 적용

	1) 딥러닝 모델이 예측값 구하는 방식

		x1, x2 두개의 입력 노드에서 들어오는 값을 기준으로 1번째 히든 레이어에서 1, 2번째 퍼셉트론에서 계산해 출력값 도출   

		1번째 히든 레이어의 1, 2번째 출력값을 2번째 히든레이어의 1,2번째 퍼셉트론에 넣어 최종 최종 출력 값이 도출 

		-> 입력값을 바탕으로 출력값을 계산하는 이 과정을 "순전파(Forward propagation)" 라고 함, 최종적인 예측값을 구할 수 있음

		ex) [ x1=1, x2=-1, w1=2, w2=1, w0=0 ] [ w3=1, w4=-1] 

		      ∑ = w1x1 + w2x2 + w0 = 1

		      activation function(x) = 0.73 

		      	※ activation function은 위에서 배운대로하면 0, 1이 나와야하는데 소수점이 나옴 -> 다른 종류의 activation function이기 때문임 

		         	우리가 배웠던 activation function은 "계단 모형"의 step function이라고 불림, 이 말고도 sigmoid, tanzent, relu 등이 있음	 

		          	언제 어떤 activation function을 쓰냐는 추후에 배우기로하고 "딥러닝 모델에 따라서 적절한 activation function을 써야함"
		
		
		      ★ 1번째 히든 레이어의 1, 2번째 출력값		

		      activation function(x) = 0.73

		      activation function(x) = 0.5

		
		      ☆ 2번째 히든 레이어에 입력
		
		      ∑ = 1*0.73 + -1*0.5 + w0 = 0.23

		      activation function(x) = 0.55

	                   예측값과 실제값 간의 오차값을 구해 손실함수를 구함, 오차값이 낮으면 손실함수값이 낮아짐
			

	2) 손실함수 최적화하는 경사하강법

		가중치는 gradient값을 사용하여 업데이트를 수행, gradient값은 각 가중치 마다 정해지며 역전파(Backpropogation)를 통해 구할 수 있음

		gradient값은 한번에 정해지지 않아 사용되는 방법이 역전파이며 결론적으로 output 가중치의 gredient를 구하고 역순으로 각 가중치의 gradient값을 계산

		편미분이 필요


	3) 정리

		i) 학습용 feature 데이터를 입력하여 예측값 구하기(순전파)

		ii) 예측값과 실제값 사이의 오차 구하기(손실함수 계산)

		iii) 손실함수를 줄일 수 있는 가중치 업데이트(역전파)

		iv) 위 과정 반복으로 손실함수 최소로 하는 가중치 얻기

-----------------------------------------------------------------------------------------------------------------------------------

텐서플로우

- 유연하고, 효율적이며, 확장성 있는 딥러닝 프레임워크

- 대형 클러스터 컴퓨터부터 스마트폰까지 다양한 디바이스에서 동작 가능

- 딥러닝 모델 구현 순서

	i) 데이터 전처리

		※ 상식 : 1차원 = vector, 2차원 = matrix, 3차원 ~ = tensor		

		ㄱ) 텐서플로우 딥러닝 모델은 Tensor 형태의 데이터를 입력 받음, Tensor란 다차원 배열로서 텐서플로우에서 사용하는 객체

		     pandas, numpy -> tensor 형태 데이터 변환 tf.data.Dataset.from_tensor_slices((featuer.values, label.values))
										    "배열"

		ㄴ) 딥러닝에 사용하는 데이터는 추가적인 전 처리 작업이 필요 -> Epoch, Bach

		     Epoch : 한 번의 epoch는 전체 데이터 셋에 대해 한 번 학습을 완료한 상태

		     Batch : 나눠진 데이터 셋, 사이즈만큼 나누게 되고 보통 mini-bach라고 표현함 .batch(batch size)

			  딥러닝 학습 과정에서 수많은 가중치 w를 업데이트 해야함, 전체 epoch을 넣는게 아닌 일부만 넣어보자에서 생긴 개념이 batch
		
			  한 epoch을 넣어 업데이트 하는 것 보다는 성능이 안 좋을 수 있지만 계산적으로는 훨씬 빠름

		     iteration : epoch을 나눠서 실행하는 횟수를 의미

		ex) 총 데이터가 1000개, batch size = 100

		     1 iteration = 100개 데이터에 대해서 학습

		     1 epoch = 1000/batch size = 10 iteration


	ii) 딥러닝 모델 구축

		ㄱ) Keras 텐서플로우의 패키지로 제공되는 고수준 API, 딥러닝 모델을 간단하고 빠르게 구현 가능

			a) keras 메소드 (1) 

				모델 클래스 객체 성성 : tf.keras.models.Sequential( ), 쉽게 말하면 딥러닝 모델을 만들 것이다 선언 = 흰 도화지 설정

				모델의 각 Layer 구성 : tf.keras.layers.Dense(units, activation), 흰 도화지에 레이어를 설계하고 만드는 과정

					units : 레이어 안의 node 수 , activation : 적용할 수 있는 activation 함수 설정


			b) input Layer 입력 형태 지정

				첫 번째 즉, input Layer는 입력 형태에 대한 정보를 필요로 함 input_shape, input_dim 인자 설정

			
				ex) model = tf.keras.models.Sequential([
					tf.keras.layers.Dense(10, input_dim=2, activation='sigmoid'), # 2개의 입력 변수, 10개의 노드, sigmoid
					tf.keras.layers.Dense(10, activation='sigmoid'), # 10개의 노드, 2번째 층
					tf.keras.layers.Dense(1, activation='sigmoid') # 1개의 노드, 3번째 층, 하나로 모여 값이 하나가 됨
			          		])

			 			입력 2, 출력 1, Hidden Layer 2

			
			
			c) keras 메소드 (2)

				모델에 Layer 추가하기

					[model].add(tf.keras.layers.Dense(units, activation))

				ex) model = tf.keras.models.Sequential( )
					
				     model.add(tf.keras.layers.Dense(10, input_dim=2, activation='sogmoid'))
				     model.add(tf.keras.layers.Dense(10, activation='sigmoid')) 
				     model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
		

	iii) 모델 학습시키기

		ㄱ) 모델 학습 방식을 설정하기 위한 함수

			[model].compile(optimizer, loss)

			optimizer : 모델 학습 최적화 방법(GD -> SGD -> Momentum -> Adam, 각자의 장단점이 있어 상황에 맞춰 사용)

			loss : 손실 함수 설정(회귀 : MSE, 분류 : Cross Entropy)

		ㄴ) 모델을 학습시키기 위한 함수

			[model].fit(x, y)

		ex) model.compile(loss='mean_squared_error', optimaizer='SGD') # MSE를 loss로 설정, 최적화 방식은 SGD

		     model.fit(dataset, epochs=100) # dataset에 저장된 데이터를 입력하고 epochs을 100으로 설정하고 학습

	iv) 평가 및 예측하기

		ㄱ) 모델을 평가하기 위한 메소드

			[model].evaluate(x, y) 

			x : 테스트 데이터 , y : 테스트 데이터의 label

		ㄴ) 모델로 예측을 수행하기 위한 함수

			[model].predict(x)

			x : 예측하고자 하는 데이터

		ex) model.evaluate(X_test, Y_test)

		     predicted_labels_test = model.predict(X_test)

-----------------------------------------------------------------------------------------------------------------------------------

이미지 처리를 위한 데이터 전처리

- 우리 주변의 이미지 처리 기술 예시

	ex) 얼굴 인식 카메라, 화질 개선(Super Resolution), 이미지 자동 태깅

- 이미지 데이터는 우리가 기존까지 다뤘던 데이터 프레임 형태의 정형화된 데이터와는 다른 비정형 데이터임

- 컴퓨터에게 이미지는 각 픽셀 값을 가진 숫자 배열로 인식 

	ex) 255, 255, 56, 88

- 이미지 전처리 하기

	i) 모두 같은 크기를 갖는 이미지로 통일 

		ㄱ) 가로 세로 픽셀 사이즈를 표현하는 해상도 통일  -> HD, FHD, 1280p,,

		ㄴ) 색을 표현하는 방식 통일 -> RGB, HSV, Gray-scale

		∴  원본 이미지 -> 해상도 변환 -> 색 표현 변환 -> MNIST 데이터(손 글씨로 된 사진을 모아둔 데이터)

	
	ii) CNN을 위한 전처리

		ㄱ) MNIST 데이터는 이미지 데이터지만 가로 길이와 세로 길이만 존재하는 2차원 데이터

		ㄴ) CNN 모델은 채널(RGB 혹은 흑백)까지 고려한 3차원 데이터를 입력으로 받기에 채널 차원을 추가해 데이터 모양(shape)을 바꿔줘야함

		ㄷ) [데이터 수, 가로 길이, 세로 길이] -> [데이터 수, 가로 길이, 세로 길이, 채널 수] 

		ㄹ) 차원 추가 함수 = tf.expand_dims(data, axis), 마지막 축(axis)에 해당하는 곳에 차원 하나를 추가할 수 있는 코드, 3 = 채널 수 3

						        -1을 넣으면 어떤 data가 들어오던 마지막 축의 index를 의미

-----------------------------------------------------------------------------------------------------------------------------------

이미지 처리를 위한 딥러닝 모델 

- 기존 다층 퍼셉트론 기반 신경망의 이미지 처리 방식

	i) 고양이 사진을 신경망에 넣는다고 가정해보자

	ii) 6X6 픽셀의 이미지라고 할 때 2차원 6X6 배열로 정의가 됨

	iii) 신경망에 넣기 위해선 1차원으로 정의를 해줘야 함 -> (1,6) (2,6) ... (6,6) 순차적으로 넣어 (36, )으로 바꿔줌 

	iv) HD사이즈 경우 극도로 많은 수의 파라미터가 필요, 또는 만약 좌우 반전, 색상 변경과 같은 이미지 변화가 있다면 같은 고양이더라도 다르게 인식하게 됨

	v) 기존의 신경망으로도 분류를 할 수 있지만 높은 픽셀일 경우 극도로 많은 수의 파라미터 필요, 좌우 반전과 같은 이미지 변화에 따른 데이터 변화가 심해 효율성이 떨어진다고 볼 수 있음

- 합성곱 신경망(Convolution Neural Network, CNN)

	i) 작은 필터를 순환시키는 방식으로 이미지의 패턴이 아닌 "특징"을 중심으로 인식, 픽셀 단위 X

		ex) 귀, 코, 수염, 꼬리

- CNN의 구조

	i) 입력 이미지의 특징을 추출, 분류하는 과정으로 동작

	ii) 고양이 사진 -> [Convolution Layer -> Pooling Layer] -> Fully-Connected Layer
				      
				CNN 		          FC(노드들이 모두 연결됨을 의미, Dense Layer)
				  
			          귀, 코, 수염		                분류

	
	iii) Convolution Layer : 이미지에서 어떠한 특징이 있는지를 구하는 과정

			   필터가 이미지를 이동하며 새로운 이미지(피쳐맵)를 생성

			   과정 : 고양이 특징 중 하나인 귀를 선택해 필터를 만듦(ex. 3X3) -> 필터가 이미지(ex. 9X9)를 꼼꼼히 이동하며 제일 비슷한 구간의 값을 피쳐맵에 "크게" 표시함
				
			            -> 비슷하지 않은 구간엔 피쳐맵에 "작게" 표시 -> 최종적인 피쳐맵에서 어떤 부분에 귀가 있고 없는지를 확인할 수 있음

			    ∴ 수 많은 필터들을 만들어 피쳐맵을 만들 수 있음, 피쳐맵은 필터와 유사한 구간을 찾아내고 위치가 표시함

				ㄱ) 피쳐맵의 크기 변형 : Padding, Striding

					- 필터를 적용하면 원본 이미지의 일부만 나오게 됨, 피쳐맵이 원본 사이즈보다 작게됨

					- 원본 사이즈랑 같게끔 나오게 하기 위해서 Padding, 원본이미지의 상하좌우에 한 줄씩 추가함

					- Striding, 필터를 이동시키는 거리를 설정함 


	iv) Pooling Layer : 이미지의 왜곡의 영향(노이즈)를 축소하는 과정,  4X4 -> 2X2

		           ㄱ) Max Pooling : 각 구간의 대표하는 max 값만을 골라 축소

		           ㄴ) Average Pooling : 각 구간의 평균값을 구해 축소

	

- Fully-Connected Layer : 추출된 특징을 사용하여 이미지를 분류

	CNN을 통해 원래 원본 이미지가 특징들이 추가된 피쳐맵이 만들어짐

	ex) 귀 피쳐맵, 입 피쳐맵 ,,,,

	피쳐맵 값들을 다시 1차원 배열로 만듦, [귀, 입, 수염,,,]


 	i) 분류를 위한 Softmax 활성화 함수

		귀 일 확률           	a
	
		입 일 확률	      -> 	b    ->  a + b + c = 1,  a + b + c <=0

		수염 일 확률        	c

- 정리 

	합성곱(특징) -> 풀링(사이즈, 노이즈) -> 활성함수

	Convolution Layer는 특징을 찾아내고, Pooling Layer는 처리할 맵(이미지) 크기를 줄여줌

	이를 N번 반복한다 -> 귀 피쳐맵 안에서도 고양이 귀만의 특징을 또 찾아냄

	반복할 때마다 줄어든 영역에서의 특징을 찾게 되고, 영역의 크기는 작아졌기 때문에 빠른 학습이 가능


- CNN 기반 다양한 이미지 처리 기술

	Object detection & segmentation - 물체들 각각을 파악함

	Super resolution(SR) - 해상도가 낮은 이미지를 높임




	1. CNN 레이어 : 입력 이미지의 특징, 즉 처리할 특징 맵(map)을 추출하는 레이어임, tf.keras.layers.Conv2D(filters, kernel_size, activation, padding)

		       					filters : 필터(커널) 개수, kernel_size : 필터(커널)의 크기, activation : 활성화 함수
							padding : 이미지가 필터를 거칠 때 그 크기가 줄어드는 것을 방지하기 위해서 가장자리에 0의 값을 가지는 픽셀을 넣을 것인지 말 것인지를 결정하는 변수, ‘SAME’ 또는 ‘VALID’

	
	2. Flatten 레이어 : Convolution layer 또는 MaxPooling layer의 결과는 N차원의 텐서 형태, 이를 1차원으로 평평하게 만들어줌, tf.keras.layers.Flatten()


	3. Dense 레이어 : tf.keras.layers.Dense(node, activation), node : 노드(뉴런) 개수activation : 활성화 함수

<모델 구현>
		import numpy as np
		import tensorflow as tf
		import matplotlib.pyplot as plt
		from visual import *
		import logging, os
		logging.disable(logging.WARNING)
		os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

		# 동일한 실행 결과 확인을 위한 코드입니다.
		np.random.seed(123)
		tf.random.set_seed(123)


		# MNIST 데이터 세트를 불러옵니다.
		mnist = tf.keras.datasets.mnist

		# MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.
		(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    

		# Train 데이터 5000개와 Test 데이터 1000개를 사용합니다.
		train_images, train_labels = train_images[:5000], train_labels[:5000]
		test_images, test_labels = test_images[:1000], test_labels[:1000]

		# CNN 모델의 입력으로 사용할 수 있도록 (샘플개수, 가로픽셀, 세로픽셀, 1) 형태로 변환합니다.
		train_images = tf.expand_dims(train_images, -1)
		test_images = tf.expand_dims(test_images, -1)


		"""
		1. CNN 모델을 설정합니다.
   		분류 모델에 맞게 마지막 레이어의 노드 수는 10개, activation 함수는 'softmax'로 설정합니다.
		"""
		model = tf.keras.Sequential([
    			tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'SAME', input_shape = (28,28,1)),
    			tf.keras.layers.MaxPool2D(padding = 'SAME'),
    			tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'SAME'),
    			tf.keras.layers.MaxPool2D(padding = 'SAME'),
    			tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'SAME'),
   			tf.keras.layers.MaxPool2D(padding = 'SAME'),
    			tf.keras.layers.Flatten(),
    			tf.keras.layers.Dense(64, activation = 'relu'),
    			tf.keras.layers.Dense(10, activation = 'softmax')
			])

		# CNN 모델 구조를 출력합니다.
		print(model.summary())

		# CNN 모델의 학습 방법을 설정합니다.
		model.compile(loss = 'sparse_categorical_crossentropy',
             		 		optimizer = 'adam',
              			metrics = ['accuracy'])
              
		# 학습을 수행합니다. 
		history = model.fit(train_images, train_labels, epochs = 20, batch_size = 512)

		# 학습 결과를 출력합니다.
		Visulaize([('CNN', history)], 'loss')


< MNIST 분류 CNN 모델 평가 및 예측> 
		
		import numpy as np
		import tensorflow as tf
		import matplotlib.pyplot as plt
		from visual import *
		from plotter import *

		import logging, os
		logging.disable(logging.WARNING)
		os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

		# 동일한 실행 결과 확인을 위한 코드입니다.
		np.random.seed(123)
		tf.random.set_seed(123)


		# MNIST 데이터 세트를 불러옵니다.
		mnist = tf.keras.datasets.mnist

		# MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.
		(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    

		# Train 데이터 5000개와 Test 데이터 1000개를 사용합니다.
		train_images, train_labels = train_images[:5000], train_labels[:5000]
		test_images, test_labels = test_images[:1000], test_labels[:1000]

		# CNN 모델의 입력으로 사용할 수 있도록 (샘플개수, 가로픽셀, 세로픽셀, 1) 형태로 변환합니다.
		train_images = tf.expand_dims(train_images, -1)
		test_images = tf.expand_dims(test_images, -1)


		# CNN 모델을 설정합니다.
		model = tf.keras.Sequential([
    			tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'SAME', input_shape = (28,28,1)),
    			tf.keras.layers.MaxPool2D(padding = 'SAME'),
    			tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'SAME'),
    			tf.keras.layers.MaxPool2D(padding = 'SAME'),
    			tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'SAME'),
    			tf.keras.layers.MaxPool2D(padding = 'SAME'),
    			tf.keras.layers.Flatten(),
    			tf.keras.layers.Dense(64, activation = 'relu'),
    			tf.keras.layers.Dense(10, activation = 'softmax')
			])

		# CNN 모델 구조를 출력합니다.
		print(model.summary())

		# CNN 모델의 학습 방법을 설정합니다.
		model.compile(loss = 'sparse_categorical_crossentropy',
              		optimizer = 'adam',
              		metrics = ['accuracy'])
              
		# 학습을 수행합니다. 
		history = model.fit(train_images, train_labels, epochs = 10, batch_size = 128, verbose = 2)

		Visulaize([('CNN', history)], 'loss')

		"""
		1. 평가용 데이터를 활용하여 모델을 평가합니다.
   		loss와 accuracy를 계산하고 loss, test_acc에 저장합니다.
		"""
		loss, test_acc = model.evaluate(test_images, test_labels, verbose = 0)

		"""
		2. 평가용 데이터에 대한 예측 결과를 predictions에 저장합니다.
		"""
		predictions = model.predict_classes(test_images)

		# 모델 평가 및 예측 결과를 출력합니다.
		print('\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))
		print('예측한 Test Data 클래스 : ',predictions[:10])

		# 평가용 데이터에 대한 레이어 결과를 시각화합니다.
		Plotter(test_images, model)

		 				

					


			     





		    

	
		

		
		   

		      




	




	
