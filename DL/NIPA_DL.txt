신경망 이전의 연구

- 사람이 직접 패턴 파악

	ex) 눈, 코, 입 / 손글씨 -> 예측 

- 인공지능의 신경망은 사람이 했던 패턴 파악을 직접 진행함

-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론(Perceptron)

- 1958년 딥러닝의 가장 기본 단위가 생겨남, 단위만으로도 간단한 회귀, 분류가 가능함

- 사람의 신경 세포를 보면 input 과 output의 구조를 가지고 있음

- input 신호를 전달 받는 부분 x1 ~ xn, n개의 돌기로 부터 전달 받음, 모두 하나로 합쳐지게 됨

- output 하나로 합쳐졌던 신호들이 y1 ~ ym, m개의 다른 신호들로 전달함 

- 이러한 신경 세포를 본떠 만든 것이 "퍼셉트론"

-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론(Perceptron)의 기본 구조

- 입력 부분

	x1, x2 입력값

- 가중치 

	w1, w2 가중치, 들어오는 신호에 대해서 얼마나 증폭시킬지 판단함
	
	입력값 x1, x2와 각각을 곱함 

- bias

	w0 bias, 입력 하는 값에 상관없이 무조건 입력되는 값

	어떤 값이던지 가능하지만 무조건 입력되는 값임

- y

	출력이 나오기 전 [입력값*가중치 + bias]은 모두 더해지고( ∑ )  마지막으로 활성화 함수(activation function)을 거져 최종적인 y값이 나옴

-----------------------------------------------------------------------------------------------------------------------------------

활성화 함수(activation function)

- activation(x) = { 1, x>=0   0, x<0 } 

	0이거나 보다 크면 1로 매핑
	
	0보다 작으면 0으로 매핑


-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론 동작 예시

	ex1) x1 = 1, x2 = 0, w1 = 2, w2 =1, bias = -0.5

		∑ = w1x1 + w2x2 + bias

	   	   = 2 + 0 - 0.5

	   	   = 1.5

		activation function(1.5) = 1

	ex2) x1 = 신작드라마 수 , x2 = 여가 시간, w1 = 드라마 시청 욕구로 인한 영향, w2 = 여가 시간에 따른 공부하고 싶은 정도, w0 = 다른 영향을 받지 않고 학습을 해야 한다는 의지

		∑ = w1x1 + w2x2 + bias

		activation function(x)

-----------------------------------------------------------------------------------------------------------------------------------

퍼셉트론을 활용한 선형 분류기

- 퍼셉트론은 선형 분류기로써 데이터 분류 가능함

- 하지만 하나의 선으로 분류할 수 없는 문제가 등장함 

- 이러한 문제가 나타나 1969년 "첫번째 AI 겨울(First AI winter)"이라고 불리는 빙하기가 찾아옴

-----------------------------------------------------------------------------------------------------------------------------------

다층 퍼셉트론

- 1986년 1차 빙하기가 해소됨

- 비 선형적인 문제 해결 

	단층 퍼셉트론은 입력층과 출력층만 존재


- 단층 퍼셉트론을 여러 층으로 쌓아보자 -> 다층 퍼셉트론 

- 단층 퍼셉트론으로 구분 하지 못했던 "결과"를 조합해 "새로운 결과"로구분해내는 모습을 볼 수 있음 

- 히든 레이어(Hidden Layer) : 입력층과 출력층 사이의 모든 Layer들

- 히든 레이어가 많아 진다면 깊은 신경망이라는 의미의 Deep Learning 단어를 사용함

	장점 : 분류할 수 있는 방법이 많아져 성능이 높아짐

	단점 : 가중치 w0, w1, w2, wn n+1 개의 가중치는 1개 퍼셉트론에 해당함 

	        즉, 다층 퍼셉트론에 필요한 가중치가 무수히 많아짐

	        마냥 깊게만 만들 수 없음 


	
